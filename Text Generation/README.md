## Text Generation
With wide variety of applications in Time Series & Deep Learning LSTM are also helpful for *Natural Language Processing*

## Long Short Term Memory Network for NLP
![](http://www.shivambansal.com/blog/text-lstm/2.png)
*Unlike regular feed forward neural networks activation output are only propogated in one direction,<br> 
but activation output in RNN & LSTM propogate in both direction. <br>
Which allows neurons to pass feedback and give ability to remember what have been learned so far.<br>
But if more layers are added to RNN it flashes with major drawback known *Vanishing Gradient Problem* which can be overcome with LSTM, with the help of additional state called 'cell state' which contain advantage of whether to remember, modify or forget the information learned so far with its gates.*
## Author
 - Prasad Patil
